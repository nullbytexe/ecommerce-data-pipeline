version: '3.8'

services:
  #postgresSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: postgres_db
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres/init.sql:/docker-entrypoint-initdb.d/01-init.sql
      - ./postgres/schema.sql:docker-entrypoint-initdb.d/02-schema.sql
    networks:
      - data-pipeline
    healthcheck:
      test: ["CMD-SHELL", pg_isready -U ${POSTGRES_USER}]
      interval: 10s
      timeout: 5s
      retries: 5

  #Kafka with Kraft (no Zookeeper)
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka_broker
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker, controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092, CONTROLLER://0.0.0.0:9093 #mở port để lắng nghe trên container kafka
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092 #quảng cáo port(nôm na là để cho container khác có thể resolve tới địa chỉ kafka bằng chính tên của kafka nhờ docker dns)
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093 # khai báo voters để map cho các controller
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1 # số bản sao offset topic (danh sách đọc đến của consumer) trong cluster
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1 # số bản sao transaction state (trạng thái giao dịch(nhiều message thành một transaction gửi hết hoặc không gửi gì hết)) trong cluster
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1 # số bản sao cần replicate trước khi có thể commit
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0 # thời gian chờ trước khi phân phối message cho các consumer - theo partition (nếu trường hợp khách hàng join và leave quá nhanh - phục vụ project thực tế(demo nên để 0))
      KAFKA_LOG_DIRS: /tmp/kraft-combined-logs
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
    volumes:
      kafka_data:/tmp/kraft-combined-logs
    networks:
      - data-pipeline
    healcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 5s
      retries: 5
  # Kafka UI
  kafka-ui:
    image: provectuslabs/kafka-ui:lastest
    container_name:kafka_ui
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTER_0_BOOTSTRAPSERVERS: kafka:9092
    depends_on:
      kafka
    networks:
      - data-pipeline

  # Redis for caching
  redis:
    image: redis:7-alpine
    container_name: redis_cache
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - data-pipeline
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

    # Producer Service
    producer:
      build:
      context: ./producer
      dockerfile: Dockerfile
      container_name:data_producer
      environment:
        KAFKA_BOOTSTRAP_SERVERS: kafka:9092
        POSTGRES_HOST: postgres
        POSTGRES_USER: ${POSTGRES_USER}
        POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
        POSTGRES_DB: ${POSTGRES_DB}
      depends_on:
        kafka:
          condition: service_healthy
        postgres:
          condition: service_healthy
        networkds:
          - data-pipeline
        restart: unless-stopped
  # Stream Processor
    build:
      context: ./stream-processor
      dockerfile: Dockerfile
    container_name: stream_processor
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      POSTGRES_HOST: postgres
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
    networks:
      - data-pipeline
    restart: unless-stopped

  # API service
  api:
    build:
      context: ./api
      dockerfile: Dockerfile
    container_name: analytics_api
    ports:
      - "5000:5000"
    environment:
      POSTGRES_HOST: postgres
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - data-pipeline
    restart: unless-stopped

networks:
  data-pipeline:
    driver: bridge

volumes:
  postgres_data:
  kafka_data:
  redis_data: